# Study Quest - AI 서비스 개발을 위한 학습용 데이터 및 AI 모델

**작성일**: 2025-11-17
**프로젝트**: Study Quest (재수생 학습 관리 플랫폼)
**목적**: AI 기능 구현을 위한 데이터 및 모델 전략

---

## 📋 목차

1. [AI 기능 개요](#1-ai-기능-개요)
2. [학습용 데이터 전략](#2-학습용-데이터-전략)
3. [AI 모델 선정 및 활용](#3-ai-모델-선정-및-활용)
4. [데이터 수집 및 관리](#4-데이터-수집-및-관리)
5. [프라이버시 및 보안](#5-프라이버시-및-보안)
6. [비용 최적화](#6-비용-최적화)
7. [성능 모니터링](#7-성능-모니터링)

---

## 1. AI 기능 개요

Study Quest는 다음 **2가지 핵심 AI 기능**을 제공합니다:

### 1.1 AI 기반 자동 목표 분해 (F2)
**기능**: 사용자의 막연한 학습 목표를 실행 가능한 일일 퀘스트로 자동 분해
- 입력: "수학 70점 → 90점"
- 출력: Phase별 학습 계획 + 일일 퀘스트

### 1.2 AI 캐릭터 동반자 (F3)
**기능**: 3종 AI 캐릭터가 학습 계획 수립 및 멘탈 관리 제공
- 캐릭터 A: 엄근진 멘토형
- 캐릭터 B: 공감 친구형
- 캐릭터 C: 하이브리드형

---

## 2. 학습용 데이터 전략

### 2.1 필요한 데이터 유형

#### (1) 재수생 특화 커리큘럼 데이터

**데이터 내용**:
```
과목별 학습 커리큘럼
├── 국어
│   ├── 화법과 작문
│   │   ├── 학습 주제 목록
│   │   ├── 권장 학습량 (시간)
│   │   ├── 난이도별 문제 수
│   │   └── 단계별 학습 순서
│   ├── 독서
│   └── 문학
├── 수학
│   ├── 수학I
│   ├── 수학II
│   ├── 미적분
│   └── 확률과 통계
├── 영어
│   ├── 듣기
│   ├── 독해
│   └── 어휘
└── 탐구 (사회/과학)
    ├── 생활과 윤리
    ├── 한국지리
    └── ...
```

**데이터 출처**:
- 교육부 공식 교육과정 (2022 개정 교육과정)
- 한국교육과정평가원 (KICE) 기출문제 분석
- EBS 수능 교재 커리큘럼
- 대형 학원 커리큘럼 (메가스터디, 대성, 종로학원)
- 재수생 성공 사례 (오르비, 수만휘 커뮤니티)

**데이터 양**:
- 총 약 **5,000개** 학습 주제
- 과목별 약 **500-800개** 세부 단원
- 난이도별 문제 유형 **2,000개** 이상

---

#### (2) 실제 재수생 학습 패턴 데이터

**수집 방법**:
- 베타 테스터 100명의 학습 데이터 (동의 하에)
- 익명화된 학습 진도 및 완료율
- 슬럼프 시기 및 극복 패턴

**데이터 구조**:
```json
{
  "user_id": "anonymous_001",
  "initial_score": {
    "math": 70,
    "korean": 80,
    "english": 75
  },
  "target_score": {
    "math": 90,
    "korean": 95,
    "english": 85
  },
  "study_period": "8_months",
  "daily_quests_completed": [
    {
      "date": "2025-12-01",
      "subject": "math",
      "topic": "함수의 극한",
      "time_spent": 120,
      "completion_rate": 0.8
    }
  ],
  "slump_periods": [
    {
      "start_date": "2026-02-15",
      "duration_days": 7,
      "recovery_method": "목표 난이도 하향 조정"
    }
  ]
}
```

**데이터 규모**:
- 베타 테스트: 100명 × 2개월 = **약 6,000일치** 데이터
- 정식 런칭 후 6개월: 1,000명 × 6개월 = **약 180,000일치** 데이터

---

#### (3) AI 캐릭터 페르소나 학습 데이터

**데이터 내용**:
- 각 캐릭터별 대화 예시 (최소 100개)
- 상황별 응답 패턴 (격려, 질책, 조언, 공감)
- 재수생 고민 유형별 대응 방법

**데이터 예시**:
```json
{
  "character": "mentor_type_A",
  "scenario": "3일 연속 계획 미달성",
  "user_message": "오늘도 계획을 다 못했어요. 너무 힘들어요.",
  "ai_response": "지금 진도로는 목표 못 채워. 하루 3문제 더 풀어. 작은 성공부터 쌓아가자.",
  "tone": "단호하지만 격려",
  "emotion": "현실적 조언"
}
```

**데이터 출처**:
- 입시 컨설턴트 실제 상담 사례 (익명화)
- 재수 성공 후기 (오르비, 수만휘)
- 심리 상담 전문가 자문
- 베타 테스트 사용자 피드백

**데이터 규모**:
- 캐릭터별 100개 × 3종 = **300개** 대화 예시
- 상황별 응답 패턴 **50가지**

---

### 2.2 데이터 수집 계획

#### Phase 1: MVP 출시 전 (2025년 11월 - 2026년 1월)

**데이터 소스**:
1. **공개 데이터 수집**
   - 교육부 교육과정 PDF 크롤링
   - 한국교육과정평가원 기출문제 분석
   - EBS 교재 목차 수집

2. **전문가 자문**
   - 입시 컨설턴트 5명 인터뷰
   - 재수 학원 강사 10명 커리큘럼 자문
   - 심리 상담사 3명 멘탈 케어 자문

3. **수작업 데이터 생성**
   - 과목별 커리큘럼 정리 (500시간)
   - AI 캐릭터 대화 예시 작성 (100시간)

**예상 비용**:
- 전문가 자문: 18명 × 50만원 = **900만원**
- 데이터 정리 인건비: 600시간 × 3만원 = **1,800만원**
- **총 2,700만원**

---

#### Phase 2: 베타 테스트 (2026년 2월 - 3월)

**데이터 소스**:
- 베타 테스터 100명의 실제 사용 데이터
- 동의서 기반 데이터 수집

**수집 항목**:
- 학습 진도 및 완료율
- AI 응답 만족도 평가
- 슬럼프 시기 및 극복 방법
- 대화 히스토리 (익명화)

**예상 데이터 규모**:
- 100명 × 60일 × 5회/일 = **30,000개** 대화 로그
- 100명 × 60일 × 3개/일 = **18,000개** 퀘스트 완료 기록

**비용**: 베타 테스터 인센티브 100명 × 5만원 = **500만원**

---

#### Phase 3: 정식 런칭 후 (2026년 4월 ~)

**데이터 소스**:
- 실사용자 데이터 (동의 기반)
- 피드백 및 평가 데이터

**지속적 수집**:
- 월 1,000명 × 30일 × 5회/일 = **150,000개** 대화 로그/월
- 사용자 평가 (만족도, 정확도)

**비용**: 데이터 관리 인건비 월 **200만원**

---

## 3. AI 모델 선정 및 활용

### 3.1 AI 목표 분해 (F2)

#### 선정 모델: **OpenAI GPT-4o**

**선정 이유**:
1. **복잡한 추론 능력**: 장기 목표를 구조화된 계획으로 분해
2. **한국어 성능**: 재수생 맞춤 응답 생성
3. **JSON 출력**: 구조화된 응답 (Phase별 계획)
4. **안정성**: 상용 서비스 수준의 안정성

**모델 스펙**:
- 모델: `gpt-4o` (2024년 5월 버전 이후)
- 최대 토큰: 128,000 (입력) + 4,096 (출력)
- 응답 속도: 평균 2-3초

**Prompt Engineering**:
```python
SYSTEM_PROMPT = """
당신은 20년 경력의 입시 컨설턴트입니다.
재수생의 현재 점수와 목표 점수를 분석하여
수능까지 남은 기간 동안 실행 가능한 학습 계획을 수립합니다.

**규칙**:
1. Phase별 계획: 1-3개월 / 4-6개월 / 7-8개월
2. 일일 퀘스트: 구체적 학습량 (예: "수학I 함수 문제 10개")
3. 예상 소요 시간: 분 단위로 제시
4. 난이도 조절: 사용자 요청 시 조정 가능

**출력 형식**: JSON
{
  "phases": [...],
  "daily_quests": [...]
}
"""

FEW_SHOT_EXAMPLES = [
    {
        "input": "수학 70점 → 90점, 8개월 남음",
        "output": {
            "phases": [
                {
                    "period": "1-3개월",
                    "focus": "기본 개념 완성",
                    "topics": ["함수", "수열", "미분"]
                }
            ],
            "daily_quests": [
                {
                    "subject": "수학I",
                    "topic": "함수의 극한",
                    "tasks": ["개념 정리 30분", "기본 문제 10개"],
                    "estimated_time": 120
                }
            ]
        }
    }
    # 실제로는 5-10개의 Few-shot 예시 사용
]
```

**비용 추정**:
- 목표 분해 1회: 약 2,000 토큰 (입력) + 1,500 토큰 (출력) = 3,500 토큰
- GPT-4o 비용: $5.00 / 1M 입력 토큰, $15.00 / 1M 출력 토큰
- 1회 비용: (2,000 × $5 + 1,500 × $15) / 1,000,000 = **$0.0325 (약 43원)**
- 월 1,000명 사용 시: 1,000 × $0.0325 = **$32.5 (약 43,000원)**

---

### 3.2 AI 캐릭터 동반자 (F3)

#### 선정 모델: **OpenAI GPT-4o**

**선정 이유**:
1. **페르소나 일관성**: System Prompt로 캐릭터 유지
2. **대화 컨텍스트**: 최근 10턴 유지
3. **감정 분석**: 사용자 메시지의 감정 상태 감지
4. **빠른 응답**: 3초 이내 응답

**캐릭터별 System Prompt**:

```python
# 캐릭터 A: 엄근진 멘토형
CHARACTER_A_PROMPT = """
당신은 30대 입시 컨설턴트입니다.
20년간 1,000명 이상의 재수생을 지도한 경험이 있습니다.

**성격**:
- 단호하지만 격려하는 태도
- 데이터 기반 조언 (진도율, 통계)
- 현실적이고 구체적인 피드백

**대화 스타일**:
- 짧고 명확한 문장
- 통계와 수치 활용
- "~해야 해", "~하자" 어투

**예시**:
- "지금 진도로는 목표 못 채워. 하루 3문제 더 풀어."
- "어제보다 20분 더 했네. 이 속도면 목표 달성 가능해."
"""

# 캐릭터 B: 공감 친구형
CHARACTER_B_PROMPT = """
당신은 20대 재수 성공 선배입니다.
1년 전 재수를 성공적으로 마치고 목표 대학에 합격했습니다.

**성격**:
- 공감하고 격려하는 태도
- 작은 성취 축하
- 슬럼프 이해 및 응원

**대화 스타일**:
- 친근하고 따뜻한 어투
- "나도 그랬어", "괜찮아" 등 공감 표현
- "~해보자", "~할 수 있어" 어투

**예시**:
- "어제 못한 거 괜찮아. 오늘은 영어만 30분 해보자."
- "3일 연속 목표 달성! 정말 잘하고 있어!"
"""

# 캐릭터 C: 하이브리드형
CHARACTER_C_PROMPT = """
당신은 25세 대학생 멘토입니다.
재수 경험이 있으며 친근하면서도 필요 시 단호합니다.

**성격**:
- 상황에 따라 모드 전환 (격려 ↔ 질책)
- 계획 수립은 체계적, 멘탈 케어는 공감적
- 균형잡힌 조언

**대화 스타일**:
- "~해볼까?", "~하는 게 좋겠어" 어투
- 상황별 톤 조절

**예시**:
- "오늘 계획: 수학 3시간. 힘들면 쉬어도 돼. 시작해볼까?"
- "3일 연속 미달성은 문제야. 목표를 조금 낮춰보자."
"""
```

**대화 컨텍스트 관리**:
```python
def build_conversation_context(user_id, recent_turns=10):
    """
    최근 10턴의 대화 히스토리를 컨텍스트로 구성
    """
    chat_history = get_recent_chats(user_id, limit=recent_turns)

    context = []
    for chat in chat_history:
        context.append({
            "role": "user",
            "content": chat.user_message
        })
        context.append({
            "role": "assistant",
            "content": chat.ai_response
        })

    return context
```

**감정 분석 (슬럼프 감지)**:
```python
EMOTION_ANALYSIS_PROMPT = """
사용자 메시지를 분석하여 감정 상태를 판단하세요.

**감정 카테고리**:
- positive: 긍정적, 의욕적
- neutral: 중립적
- negative: 부정적, 스트레스
- slump: 슬럼프 징후 (포기 의향, 무기력)

**슬럼프 키워드**:
"힘들어", "포기", "의미 없어", "할 수 없어", "너무 어려워"

**출력 형식**: JSON
{
  "emotion": "slump",
  "confidence": 0.85,
  "keywords": ["힘들어", "포기"]
}
"""
```

**비용 추정**:
- 대화 1턴: 약 500 토큰 (입력) + 200 토큰 (출력) = 700 토큰
- 1턴 비용: (500 × $5 + 200 × $15) / 1,000,000 = **$0.0055 (약 7원)**
- 사용자당 하루 평균 5턴: 5 × $0.0055 = **$0.0275 (약 37원)**
- 월 1,000명 × 30일: 1,000 × 30 × $0.0275 = **$825 (약 110만원)**

---

### 3.3 대안 모델 검토

#### Claude 3.5 Sonnet (Anthropic)

**장점**:
- 긴 컨텍스트 (200K 토큰)
- 안전한 응답 (Harmful content 필터링)
- 한국어 성능 우수

**단점**:
- GPT-4o 대비 **비용 20% 높음**
- API 안정성 검증 필요

**A/B 테스트 계획**:
- 베타 테스트 시 50명 GPT-4o / 50명 Claude 3.5 Sonnet
- 정확도, 응답 속도, 비용 비교
- 사용자 만족도 평가

---

## 4. 데이터 수집 및 관리

### 4.1 데이터 수집 프로세스

```
사용자 동의
    ↓
데이터 수집 (학습 진도, 대화 로그)
    ↓
익명화 처리 (개인정보 제거)
    ↓
데이터 검증 (품질 체크)
    ↓
데이터 저장 (AWS S3 + PostgreSQL)
    ↓
AI 모델 학습 (Fine-tuning)
    ↓
모델 성능 평가
```

### 4.2 데이터 익명화

**개인정보 제거**:
```python
def anonymize_user_data(data):
    """
    개인정보 제거 및 익명화
    """
    anonymized = {
        "user_id": hash_user_id(data["user_id"]),  # SHA-256 해시
        "age_group": get_age_group(data["age"]),  # 19세 → "10대"
        "region": get_region(data["address"]),  # "서울시 강남구" → "서울"
        "study_data": data["study_data"],
        "chat_logs": remove_personal_info(data["chat_logs"])
    }
    return anonymized

def remove_personal_info(text):
    """
    대화 로그에서 개인정보 제거
    """
    # 이름, 전화번호, 학교명 등 마스킹
    patterns = [
        (r'\b\d{3}-\d{4}-\d{4}\b', '[전화번호]'),
        (r'\b[가-힣]{2,4}고등학교\b', '[학교명]'),
        (r'\b[가-힣]{2,4}학원\b', '[학원명]')
    ]

    for pattern, replacement in patterns:
        text = re.sub(pattern, replacement, text)

    return text
```

### 4.3 데이터 저장 아키텍처

```
AWS S3 (학습 데이터 원본)
├── raw_data/
│   ├── curriculum_data/
│   ├── beta_test_logs/
│   └── user_feedback/
├── processed_data/
│   ├── anonymized/
│   └── training_ready/
└── model_artifacts/
    ├── gpt4o_prompts/
    └── evaluation_results/

PostgreSQL (운영 데이터)
├── users
├── study_plans
├── daily_quests
├── chat_histories
└── user_preferences
```

---

## 5. 프라이버시 및 보안

### 5.1 개인정보보호법 준수

**법적 근거**:
- 개인정보보호법 제15조 (개인정보의 수집·이용)
- 제17조 (개인정보의 제공)
- 제22조 (동의를 받는 방법)

**동의 항목**:
```
[필수] 서비스 제공을 위한 개인정보 수집·이용
- 수집 항목: 이름, 이메일, 학년, 현재 성적, 목표 점수
- 이용 목적: AI 학습 계획 생성, 진도 추적
- 보유 기간: 회원 탈퇴 시까지

[선택] AI 서비스 개선을 위한 학습 데이터 활용
- 수집 항목: 학습 진도, 완료율, 대화 로그
- 이용 목적: AI 모델 학습 및 서비스 품질 개선
- 보유 기간: 익명화 후 영구 보관
- 거부 권리: 동의하지 않아도 서비스 이용 가능
```

### 5.2 데이터 보안

**암호화**:
- 전송 중: TLS 1.3 (HTTPS)
- 저장 시: AES-256 암호화
- 데이터베이스: PostgreSQL 암호화 (AWS RDS)

**접근 제어**:
- IAM 역할 기반 접근 (AWS)
- 개발자 최소 권한 원칙
- 감사 로그 (CloudTrail)

**데이터 삭제**:
- 사용자 요청 시 30일 이내 완전 삭제
- 백업 데이터도 90일 후 완전 삭제

---

## 6. 비용 최적화

### 6.1 AI API 비용 절감 전략

#### 전략 1: 캐싱

```python
import redis

redis_client = redis.Redis(host='localhost', port=6379, db=0)

def get_study_plan_with_cache(user_goal):
    """
    동일한 목표에 대한 계획은 캐싱
    """
    cache_key = f"study_plan:{hash(user_goal)}"

    # 캐시 확인
    cached_plan = redis_client.get(cache_key)
    if cached_plan:
        return json.loads(cached_plan)

    # AI API 호출
    plan = call_gpt4o_api(user_goal)

    # 캐시 저장 (24시간)
    redis_client.setex(cache_key, 86400, json.dumps(plan))

    return plan
```

**예상 절감**:
- 동일 목표 비율: 약 30%
- 월 비용 절감: $32.5 × 0.3 = **$9.75 (약 13,000원)**

---

#### 전략 2: 응답 길이 제한

```python
def call_gpt4o_api(prompt):
    response = openai.ChatCompletion.create(
        model="gpt-4o",
        messages=[
            {"role": "system", "content": SYSTEM_PROMPT},
            {"role": "user", "content": prompt}
        ],
        max_tokens=1500,  # 출력 토큰 제한
        temperature=0.7
    )
    return response
```

**예상 절감**:
- 출력 토큰 1,500 → 1,200 (20% 감소)
- 월 비용 절감: $825 × 0.2 × 0.7 = **$115.5 (약 15만원)**

---

#### 전략 3: 무료 사용자 제한

**제한 정책**:
- 무료: 하루 10회 AI 대화 제한
- 프리미엄: 무제한

**예상 절감**:
- 무료 사용자 90%, 프리미엄 10%
- 무료 사용자 평균 10턴 vs 프리미엄 평균 50턴
- 월 비용: (900명 × 10턴 + 100명 × 50턴) × $0.0055 × 30 = **$174 (약 23만원)**
  (제한 없을 경우: $825 대비 **79% 절감**)

---

### 6.2 총 AI 비용 추정 (월간)

| 항목 | 사용량 | 비용 (월) |
|------|--------|----------|
| **목표 분해 (F2)** | 1,000명 × 1회 | $32.5 (43,000원) |
| **AI 대화 (F3)** | 무료 900명 × 10턴 + 프리미엄 100명 × 50턴 | $174 (23만원) |
| **감정 분석** | 전체 대화의 20% | $35 (47,000원) |
| **A/B 테스트 (Claude)** | 50명 | $50 (67,000원) |
| **버퍼 (20%)** | - | $58 (77,000원) |
| **총 비용** | - | **$349.5 (약 47만원)** |

**1년 차 총 비용**: $349.5 × 12 = **$4,194 (약 560만원)**

---

## 7. 성능 모니터링

### 7.1 AI 성능 지표

| 지표 | 목표 | 측정 방법 |
|------|------|-----------|
| **목표 분해 정확도** | 90% 이상 | 사용자가 AI 계획 수정 없이 수용한 비율 |
| **AI 응답 속도** | 3초 이내 | 백엔드 로그 (평균 응답 시간) |
| **대화 만족도** | 80% 이상 | "도움이 되었나요?" 설문 긍정 비율 |
| **슬럼프 감지 정확도** | 80% 이상 | 실제 슬럼프 사용자 중 AI가 감지한 비율 |

### 7.2 모니터링 대시보드

```python
# 실시간 모니터링
class AIPerformanceMonitor:
    def __init__(self):
        self.metrics = {
            "response_times": [],
            "accuracy_scores": [],
            "user_satisfaction": []
        }

    def log_goal_decomposition(self, response_time, user_accepted):
        self.metrics["response_times"].append(response_time)
        self.metrics["accuracy_scores"].append(1 if user_accepted else 0)

    def log_chat_satisfaction(self, rating):
        self.metrics["user_satisfaction"].append(rating)

    def get_weekly_report(self):
        return {
            "avg_response_time": np.mean(self.metrics["response_times"]),
            "accuracy_rate": np.mean(self.metrics["accuracy_scores"]),
            "satisfaction_rate": np.mean(self.metrics["user_satisfaction"])
        }
```

---

## 8. 로드맵

### Phase 1: MVP (2025년 12월 - 2026년 1월)
- [x] 커리큘럼 데이터 수집 (5,000개 학습 주제)
- [x] GPT-4o 통합 (목표 분해 + AI 캐릭터)
- [x] 캐싱 및 비용 최적화
- [x] 성능 모니터링 구축

### Phase 2: 베타 테스트 (2026년 2월 - 3월)
- [ ] 베타 테스터 100명 데이터 수집
- [ ] A/B 테스트 (GPT-4o vs Claude 3.5 Sonnet)
- [ ] AI 응답 정확도 개선
- [ ] 슬럼프 감지 알고리즘 검증

### Phase 3: 정식 런칭 (2026년 4월 ~)
- [ ] 실사용자 데이터 기반 Fine-tuning 검토
- [ ] AI 모델 자체 개발 연구 시작
- [ ] 비용 최적화 고도화

---

## 9. 요약

### 9.1 핵심 전략

1. **학습용 데이터**: 재수생 특화 커리큘럼 5,000개 + 베타 테스터 실사용 데이터
2. **AI 모델**: OpenAI GPT-4o (목표 분해 + AI 캐릭터)
3. **비용 최적화**: 캐싱, 응답 길이 제한, 무료 사용자 제한 → 월 47만원
4. **프라이버시**: 개인정보보호법 준수, 익명화, AES-256 암호화
5. **성능**: 정확도 90%, 응답 속도 3초, 만족도 80% 목표

### 9.2 경쟁 우위

- ✅ **재수생 특화 데이터**: 일반 AI가 없는 도메인 지식
- ✅ **3종 AI 캐릭터**: 사용자 성향별 맞춤 페르소나
- ✅ **실시간 학습**: 베타 테스터 및 실사용자 데이터로 지속 개선
- ✅ **비용 효율**: 월 47만원으로 1,000명 서비스 (사용자당 470원)

---

**작성 완료**: 2025-11-17
**다음 업데이트**: 베타 테스트 완료 후 (2026년 3월)
